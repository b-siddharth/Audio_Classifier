{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3489434e-0308-4964-bfa6-1f21f2b37d8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /Users/siddharth_b/miniforge3/lib/python3.10/site-packages (2.13.0)\n",
      "Requirement already satisfied: tensorflow-macos==2.13.0 in /Users/siddharth_b/miniforge3/lib/python3.10/site-packages (from tensorflow) (2.13.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Users/siddharth_b/miniforge3/lib/python3.10/site-packages (from tensorflow-macos==2.13.0->tensorflow) (2.0.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/siddharth_b/miniforge3/lib/python3.10/site-packages (from tensorflow-macos==2.13.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in /Users/siddharth_b/miniforge3/lib/python3.10/site-packages (from tensorflow-macos==2.13.0->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /Users/siddharth_b/miniforge3/lib/python3.10/site-packages (from tensorflow-macos==2.13.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/siddharth_b/miniforge3/lib/python3.10/site-packages (from tensorflow-macos==2.13.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /Users/siddharth_b/miniforge3/lib/python3.10/site-packages (from tensorflow-macos==2.13.0->tensorflow) (3.9.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Users/siddharth_b/miniforge3/lib/python3.10/site-packages (from tensorflow-macos==2.13.0->tensorflow) (16.0.6)\n",
      "Requirement already satisfied: numpy<=1.24.3,>=1.22 in /Users/siddharth_b/miniforge3/lib/python3.10/site-packages (from tensorflow-macos==2.13.0->tensorflow) (1.24.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/siddharth_b/miniforge3/lib/python3.10/site-packages (from tensorflow-macos==2.13.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in /Users/siddharth_b/miniforge3/lib/python3.10/site-packages (from tensorflow-macos==2.13.0->tensorflow) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /Users/siddharth_b/miniforge3/lib/python3.10/site-packages (from tensorflow-macos==2.13.0->tensorflow) (4.24.3)\n",
      "Requirement already satisfied: setuptools in /Users/siddharth_b/miniforge3/lib/python3.10/site-packages (from tensorflow-macos==2.13.0->tensorflow) (68.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/siddharth_b/miniforge3/lib/python3.10/site-packages (from tensorflow-macos==2.13.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/siddharth_b/miniforge3/lib/python3.10/site-packages (from tensorflow-macos==2.13.0->tensorflow) (2.3.0)\n",
      "Collecting typing-extensions<4.6.0,>=3.6.6 (from tensorflow-macos==2.13.0->tensorflow)\n",
      "  Using cached typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/siddharth_b/miniforge3/lib/python3.10/site-packages (from tensorflow-macos==2.13.0->tensorflow) (1.15.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/siddharth_b/miniforge3/lib/python3.10/site-packages (from tensorflow-macos==2.13.0->tensorflow) (1.58.0)\n",
      "Requirement already satisfied: tensorboard<2.14,>=2.13 in /Users/siddharth_b/miniforge3/lib/python3.10/site-packages (from tensorflow-macos==2.13.0->tensorflow) (2.13.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in /Users/siddharth_b/miniforge3/lib/python3.10/site-packages (from tensorflow-macos==2.13.0->tensorflow) (2.13.0)\n",
      "Requirement already satisfied: keras<2.14,>=2.13.1 in /Users/siddharth_b/miniforge3/lib/python3.10/site-packages (from tensorflow-macos==2.13.0->tensorflow) (2.13.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/siddharth_b/miniforge3/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow-macos==2.13.0->tensorflow) (0.41.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /Users/siddharth_b/miniforge3/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (2.23.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /Users/siddharth_b/miniforge3/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/siddharth_b/miniforge3/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (3.4.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/siddharth_b/miniforge3/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/siddharth_b/miniforge3/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (0.7.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/siddharth_b/miniforge3/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (2.3.7)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/siddharth_b/miniforge3/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/siddharth_b/miniforge3/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/siddharth_b/miniforge3/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: urllib3<2.0 in /Users/siddharth_b/miniforge3/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (1.26.16)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/siddharth_b/miniforge3/lib/python3.10/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/siddharth_b/miniforge3/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/siddharth_b/miniforge3/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/siddharth_b/miniforge3/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/siddharth_b/miniforge3/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /Users/siddharth_b/miniforge3/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/siddharth_b/miniforge3/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (3.2.2)\n",
      "Installing collected packages: typing-extensions\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.8.0\n",
      "    Uninstalling typing_extensions-4.8.0:\n",
      "      Successfully uninstalled typing_extensions-4.8.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pydantic 2.4.2 requires typing-extensions>=4.6.1, but you have typing-extensions 4.5.0 which is incompatible.\n",
      "pydantic-core 2.10.1 requires typing-extensions!=4.7.0,>=4.6.0, but you have typing-extensions 4.5.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed typing-extensions-4.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c519c77-c216-49bf-805c-55bb73a0119e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow-io\n",
      "  Obtaining dependency information for tensorflow-io from https://files.pythonhosted.org/packages/ab/15/60e87d8090d1fe9fda0234c7e6f6b83cd522311164704daecb3f8450fb7f/tensorflow_io-0.34.0-cp310-cp310-macosx_12_0_arm64.whl.metadata\n",
      "  Downloading tensorflow_io-0.34.0-cp310-cp310-macosx_12_0_arm64.whl.metadata (14 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem==0.34.0 (from tensorflow-io)\n",
      "  Obtaining dependency information for tensorflow-io-gcs-filesystem==0.34.0 from https://files.pythonhosted.org/packages/fe/ba/4af347fc269893a42ad9eff66aa6330032220b41b02ba31a407e89812e48/tensorflow_io_gcs_filesystem-0.34.0-cp310-cp310-macosx_12_0_arm64.whl.metadata\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.34.0-cp310-cp310-macosx_12_0_arm64.whl.metadata (14 kB)\n",
      "Downloading tensorflow_io-0.34.0-cp310-cp310-macosx_12_0_arm64.whl (34.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.9/34.9 MB\u001b[0m \u001b[31m692.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow_io_gcs_filesystem-0.34.0-cp310-cp310-macosx_12_0_arm64.whl (1.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m711.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tensorflow-io-gcs-filesystem, tensorflow-io\n",
      "Successfully installed tensorflow-io-0.34.0 tensorflow-io-gcs-filesystem-0.34.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow-io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66d313ec-47c9-4cac-a736-d3e256bca684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow-io in /Users/siddharth_b/miniforge3/lib/python3.10/site-packages (0.34.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem==0.34.0 in /Users/siddharth_b/miniforge3/lib/python3.10/site-packages (from tensorflow-io) (0.34.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade tensorflow-io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "91dd506e-2bd4-46a7-bbe5-1c9993e0b230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: tensorflow\n",
      "Version: 2.13.0\n",
      "Summary: TensorFlow is an open source machine learning framework for everyone.\n",
      "Home-page: https://www.tensorflow.org/\n",
      "Author: Google Inc.\n",
      "Author-email: packages@tensorflow.org\n",
      "License: Apache 2.0\n",
      "Location: /Users/siddharth_b/miniforge3/lib/python3.10/site-packages\n",
      "Requires: tensorflow-macos\n",
      "Required-by: \n",
      "---\n",
      "Name: tensorflow-io\n",
      "Version: 0.34.0\n",
      "Summary: TensorFlow IO\n",
      "Home-page: https://github.com/tensorflow/io\n",
      "Author: Google Inc.\n",
      "Author-email: opensource@google.com\n",
      "License: \n",
      "Location: /Users/siddharth_b/miniforge3/lib/python3.10/site-packages\n",
      "Requires: tensorflow-io-gcs-filesystem\n",
      "Required-by: \n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show tensorflow tensorflow-io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1f55dfaf-df54-4fc2-b7df-3af6997227fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement tensorflow==2.4.1 (from versions: 2.13.0rc0, 2.13.0rc1, 2.13.0rc2, 2.13.0, 2.13.1, 2.14.0rc0, 2.14.0rc1, 2.14.0, 2.15.0rc0, 2.15.0rc1)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for tensorflow==2.4.1\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow==2.4.1 tensorflow-io==0.18.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8627d148-3852-4ff9-a7e5-a59b8b16b29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf \n",
    "import tensorflow_io as tfio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d56f823-613e-46bf-9a96-e0e62264a674",
   "metadata": {},
   "outputs": [],
   "source": [
    "CAPUCHIN_FILE = os.path.join('data', 'Parsed_Capuchinbird_Clips', 'XC3776-3.wav')\n",
    "NOT_CAPUCHIN_FILE = os.path.join('data', 'Parsed_Not_Capuchinbird_Clips', 'afternoon-birds-song-in-forest-0.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "25c2726d-69c3-4c4d-9595-4ecd6d859994",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/Parsed_Capuchinbird_Clips/XC3776-3.wav'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CAPUCHIN_FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "99e8b9de-8ddb-4d6a-9ec6-189c70de3cc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/Parsed_Not_Capuchinbird_Clips/afternoon-birds-song-in-forest-0.wav'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NOT_CAPUCHIN_FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7ce6b118-634b-47ca-9262-1fb33c9ad79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_wav_16k_mono(filename):\n",
    "    # Load encoded wav file\n",
    "    file_contents = tf.io.read_file(filename)\n",
    "    # Decode wav (tensors by channels) \n",
    "    wav, sample_rate = tf.audio.decode_wav(file_contents, desired_channels=1)\n",
    "    # Removes trailing axis\n",
    "    wav = tf.squeeze(wav, axis=-1)\n",
    "    sample_rate = tf.cast(sample_rate, dtype=tf.int64)\n",
    "    # Goes from 44100Hz to 16000hz - amplitude of the audio signal\n",
    "    wav = tfio.audio.resample(wav, rate_in=sample_rate, rate_out=16000)\n",
    "    return wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "441ccda2-f74c-42ac-af0d-f0abda80ed53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_wav_16k_mono(filename):\n",
    "    # Load encoded wav file\n",
    "    file_contents = tf.io.read_file(filename)\n",
    "    # Decode wav (tensors by channels) \n",
    "    wav, sample_rate = tf.audio.decode_wav(file_contents, desired_channels=1)\n",
    "    # Removes trailing axis\n",
    "    wav = tf.squeeze(wav, axis=-1)\n",
    "    sample_rate = tf.cast(sample_rate, dtype=tf.int64)\n",
    "    # Goes from 44100Hz to 16000hz - amplitude of the audio signal\n",
    "    wav = tfio.audio.resample(wav, rate_in=sample_rate, rate_out=16000)\n",
    "    return wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd56c3b-27bc-4dc9-8417-c533a8008cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "wave = load_wav_16k_mono(CAPUCHIN_FILE)\n",
    "nwave = load_wav_16k_mono(NOT_CAPUCHIN_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3905e6-289e-4250-ab12-3c49e9705265",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(wave)\n",
    "plt.plot(nwave)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c42daae-1d08-4361-9452-c43d84e22e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "POS = os.path.join('data', 'Parsed_Capuchinbird_Clips')\n",
    "NEG = os.path.join('data', 'Parsed_Not_Capuchinbird_Clips')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ce2a42-a744-43cc-b4f2-f0b6eb34f7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = tf.data.Dataset.list_files(POS+'\\*.wav')\n",
    "neg = tf.data.Dataset.list_files(NEG+'\\*.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b81358-f9f6-41eb-86c4-ae3e62924ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "positives = tf.data.Dataset.zip((pos, tf.data.Dataset.from_tensor_slices(tf.ones(len(pos)))))\n",
    "negatives = tf.data.Dataset.zip((neg, tf.data.Dataset.from_tensor_slices(tf.zeros(len(neg)))))\n",
    "data = positives.concatenate(negatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9b06c7-fd31-4885-bb98-4cb9aca681d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = []\n",
    "for file in os.listdir(os.path.join('data', 'Parsed_Capuchinbird_Clips')):\n",
    "    tensor_wave = load_wav_16k_mono(os.path.join('data', 'Parsed_Capuchinbird_Clips', file))\n",
    "    lengths.append(len(tensor_wave))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e942e951-6bf3-4da5-9ce5-37c33fd7adf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.math.reduce_mean(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672fedba-aeec-4b6d-85d1-50474a111998",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.math.reduce_min(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090d0b8b-ec40-4158-98c5-01986d44daf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.math.reduce_max(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5ed69b-ad0e-49f4-860f-b508eda4277c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(file_path, label): \n",
    "    wav = load_wav_16k_mono(file_path)\n",
    "    wav = wav[:48000]\n",
    "    zero_padding = tf.zeros([48000] - tf.shape(wav), dtype=tf.float32)\n",
    "    wav = tf.concat([zero_padding, wav],0)\n",
    "    spectrogram = tf.signal.stft(wav, frame_length=320, frame_step=32)\n",
    "    spectrogram = tf.abs(spectrogram)\n",
    "    spectrogram = tf.expand_dims(spectrogram, axis=2)\n",
    "    return spectrogram, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80e7ee7-f88a-4ddf-8a1d-51a61b4ee330",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath, label = positives.shuffle(buffer_size=10000).as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f75b5a8-10c8-4b86-bcfd-896b079b8e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrogram, label = preprocess(filepath, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abf8d7d-d8bd-4ec3-a54f-f2f0fcd016fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30,20))\n",
    "plt.imshow(tf.transpose(spectrogram)[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9a5085-a303-4642-9f7c-e158f1e62b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.map(preprocess)\n",
    "data = data.cache()\n",
    "data = data.shuffle(buffer_size=1000)\n",
    "data = data.batch(16)\n",
    "data = data.prefetch(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd8ce2f-a9d1-43af-928c-915e33314c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data.take(36)\n",
    "test = data.skip(36).take(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef4b74a-bbdc-42db-bac3-ef4532b51d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples, labels = train.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b43905a-0dea-48ec-878b-446367345242",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176dd16e-cee9-4aef-8e48-760e457d33bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Dense, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bd2e8c-0ce1-475a-9015-e7f898bce378",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(16, (3,3), activation='relu', input_shape=(1491, 257,1)))\n",
    "model.add(Conv2D(16, (3,3), activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e037d9-d8ad-4f83-bbf3-60a976e74d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile('Adam', loss='BinaryCrossentropy', metrics=[tf.keras.metrics.Recall(),tf.keras.metrics.Precision()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9c32d1-7d22-4e34-a1ae-13d49955092b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b4ad4a-f647-4c2e-8465-6cd68826c661",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = model.fit(train, epochs=4, validation_data=test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0450f19-d78e-4ed5-a666-5d71f8b38688",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Loss')\n",
    "plt.plot(hist.history['loss'], 'r')\n",
    "plt.plot(hist.history['val_loss'], 'b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9d873e-6fad-4f2e-87e0-d24044ff9f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Precision')\n",
    "plt.plot(hist.history['precision'], 'r')\n",
    "plt.plot(hist.history['val_precision'], 'b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6d104b-9d9f-4631-a51b-9f8453275f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Recall')\n",
    "plt.plot(hist.history['recall'], 'r')\n",
    "plt.plot(hist.history['val_recall'], 'b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72f4f18-c97e-460e-a558-4da59e2adeff",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = test.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af76fc3-e89b-4c7a-815e-5a86c4c9d603",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3713ed67-2672-47ed-ba96-d5b91faa6af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = [1 if prediction > 0.5 else 0 for prediction in yhat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0b1924-750a-4e99-8d70-f60a94dc7306",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mp3_16k_mono(filename):\n",
    "    \"\"\" Load a WAV file, convert it to a float tensor, resample to 16 kHz single-channel audio. \"\"\"\n",
    "    res = tfio.audio.AudioIOTensor(filename)\n",
    "    # Convert to tensor and combine channels \n",
    "    tensor = res.to_tensor()\n",
    "    tensor = tf.math.reduce_sum(tensor, axis=1) / 2 \n",
    "    # Extract sample rate and cast\n",
    "    sample_rate = res.rate\n",
    "    sample_rate = tf.cast(sample_rate, dtype=tf.int64)\n",
    "    # Resample to 16 kHz\n",
    "    wav = tfio.audio.resample(tensor, rate_in=sample_rate, rate_out=16000)\n",
    "    return wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e016121-0ae4-40f2-b90d-f0cc244d751a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp3 = os.path.join('data', 'Forest Recordings', 'recording_00.mp3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b29a2e5-23c1-4e12-8076-459b566883c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "wav = load_mp3_16k_mono(mp3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e9e0da-95aa-49a2-af36-03dab6bf1902",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_slices = tf.keras.utils.timeseries_dataset_from_array(wav, wav, sequence_length=48000, sequence_stride=48000, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8b0e88-45f5-47a8-b66a-86f998bb052b",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples, index = audio_slices.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b6d9c6-1af3-43f1-accf-222113a83344",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_mp3(sample, index):\n",
    "    sample = sample[0]\n",
    "    zero_padding = tf.zeros([48000] - tf.shape(sample), dtype=tf.float32)\n",
    "    wav = tf.concat([zero_padding, sample],0)\n",
    "    spectrogram = tf.signal.stft(wav, frame_length=320, frame_step=32)\n",
    "    spectrogram = tf.abs(spectrogram)\n",
    "    spectrogram = tf.expand_dims(spectrogram, axis=2)\n",
    "    return spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3daa5194-75ca-4bc7-8e3e-856958baf865",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_slices = tf.keras.utils.timeseries_dataset_from_array(wav, wav, sequence_length=16000, sequence_stride=16000, batch_size=1)\n",
    "audio_slices = audio_slices.map(preprocess_mp3)\n",
    "audio_slices = audio_slices.batch(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd0387c-4311-4201-95b3-0f7ab1c9e1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = model.predict(audio_slices)\n",
    "yhat = [1 if prediction > 0.5 else 0 for prediction in yhat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b3bca4-7b63-47ae-b2b7-ffffa0a6f5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6121c1-2a00-4580-a96c-78a46ceccd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = [key for key, group in groupby(yhat)]\n",
    "calls = tf.math.reduce_sum(yhat).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5148b2-ce57-434c-9563-203a736db494",
   "metadata": {},
   "outputs": [],
   "source": [
    "calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a179035-6c54-45c5-94a9-e826735faac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "for file in os.listdir(os.path.join('data', 'Forest Recordings')):\n",
    "    FILEPATH = os.path.join('data','Forest Recordings', file)\n",
    "    \n",
    "    wav = load_mp3_16k_mono(FILEPATH)\n",
    "    audio_slices = tf.keras.utils.timeseries_dataset_from_array(wav, wav, sequence_length=48000, sequence_stride=48000, batch_size=1)\n",
    "    audio_slices = audio_slices.map(preprocess_mp3)\n",
    "    audio_slices = audio_slices.batch(64)\n",
    "    \n",
    "    yhat = model.predict(audio_slices)\n",
    "    \n",
    "    results[file] = yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3605eb-16f2-478d-a502-49e31fd19dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb0fb50-0915-4ab6-a52c-83181cfd3eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_preds = {}\n",
    "for file, logits in results.items():\n",
    "    class_preds[file] = [1 if prediction > 0.99 else 0 for prediction in logits]\n",
    "class_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc7c482-3d55-482f-97cb-45883d7b2481",
   "metadata": {},
   "outputs": [],
   "source": [
    "postprocessed = {}\n",
    "for file, scores in class_preds.items():\n",
    "    postprocessed[file] = tf.math.reduce_sum([key for key, group in groupby(scores)]).numpy()\n",
    "postprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23f66e1-035e-4f83-b83d-941956ac1251",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6927a3ae-88c3-4937-8ee2-2631ea608f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('results.csv', 'w', newline='') as f:\n",
    "    writer = csv.writer(f, delimiter=',')\n",
    "    writer.writerow(['recording', 'capuchin_calls'])\n",
    "    for key, value in postprocessed.items():\n",
    "        writer.writerow([key, value])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
